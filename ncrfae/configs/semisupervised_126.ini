[hyperparams]
pretrained_model="bert"
encode_method="endpoint"
norm=True
max_length=-1
partition_length=-1
supvised_part=0.1
model="kmeansbiaffinencrfae"
kcluster=50
word_embed=True
method="head_selection"
unsupervised_weight=0.0001
embed_dropout=.33
n_lstm_hidden=200
n_lstm_layers=2
lstm_dropout=.33
n_mlp_arc=200
n_mlp_rel=100
mlp_dropout=.33
encode_prob=False
identity_biaffine=False
lr=1e-3
mu=.9
nu=.9
epsilon=1e-12
l2reg=1e-5
clip=5.0
decay=1.0
decay_steps=5000
init_epoch=20
smooth="uniform"
alpha=10.0
decoder_learn=True
batch_size=1000
epochs=300
random_seed=42