[hyperparams]
pretrained_model="bert"
encode_method="endpoint"
norm=True
model='biaffineae'
n_embed=200
embed_dropout=.33
n_lstm_hidden=400
n_lstm_layers=1
lstm_dropout=.33
n_mlp_arc=500
n_mlp_rel=200
mlp_dropout=.33
lr=1e-3
mu=.9
nu=.9
epsilon=1e-12
l2reg=1e-4
clip=5.0
decay=.75
decay_steps=5000
smooth='uniform'
alpha=1.0
decoder_learn=True
batch_size=5000
epochs=1000
random_seed=42
kcluster=50